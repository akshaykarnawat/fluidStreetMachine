version: 2.1

executors:
  my-executor:
    docker:
      # - image: cimg/python:3.11.2
      - image: cimg/aws:2023.03
    resource_class: small
    working_directory: ~/workspace

commands:
  install_python:
    steps:
      - run:
          name: install python in environment
          command: |
            sudo apt-get update
            sudo apt-get install python3.11
  create_virtual_env:
    steps:
      - run:
          name: create a virual environment
          command: |
            pip3 install --upgrade pip
            pip3 install --user virtualenv
            virtualenv venv
            source venv/bin/activate
  get_schema_change_repo:
    steps:
      - run:
          name: getting schemachange repo
          command: |
            git clone https://github.com/Snowflake-Labs/schemachange.git --depth=1
            # pip3 install numpy requests $(cat schemachange/requirements.txt | awk -F== '{print $1}')
            # python3 schemachange/schemachange/cli.py -h

jobs:
  fetch-code:
    description: Checkout codebase
    # machine:
    #   image: ubuntu-2204:2022.07.1
    # resource_class: medium
    executor: my-executor
    steps:
      - checkout # check out the code in the project directory
      - install_python
      - create_virtual_env
      - get_schema_change_repo
      - run: pwd; ls -la
      - persist_to_workspace:
          root: ./
          paths:
            - ./

  build-code:
    description: building the codebase and running through the test cases
    executor: my-executor
    steps:
      - attach_workspace:
          at: ~/workspace
      - run: pwd; ls -la
      - run: source venv/bin/activate
      - run:
          name: installing requirements
          command: pip3 install -r requirements.txt
      - run:
          name: clean, lint, and static scan codebase
          command: pre-commit run --all-files
      - run:
          name: test codebase
          command: echo unit testing and code coverage of the build
      - run:
          name: build codebase
          command: zip -r ./artifact.zip . -x ".git/*" -x "venv/*" -x "schemachange/*"
      - store_artifacts:
          path: ./artifact.zip
          destination: artifact
      - persist_to_workspace:
          root: ./
          paths:
            - ./

  deploy-dev:
    executor: my-executor
    steps:
      - attach_workspace:
          at: ~/workspace
      - run: source venv/bin/activate
      - run:
          name: installing schemachange requirements
          command: pip3 install numpy requests $(cat schemachange/requirements.txt | awk -F== '{print $1}')
      - run: echo deploying the codebase to the dev snowflake env
      - run:
          name: snowflake deployment
          command: |
            SNOWFLAKE_AUTHENTICATOR=snowflake \
            python3 schemachange/schemachange/cli.py \
            -f ./databases/snowflake/migrations \
            -a ${SNOWFLAKE_ACCOUNT} \
            -u ${SNOWFLAKE_USER} \
            -r ${SNOWFLAKE_ROLE} \
            -w ${SNOWFLAKE_WAREHOUSE} \
            -d ${SNOWFLAKE_DATABASE} \
            -c ${SNOWFLAKE_DATABASE}.${SNOWFLAKE_SCHEMA}.CHANGE_HISTORY \
            --query-tag DATA_ENGINEERING \
            --vars "{\"DB\": \"${SNOWFLAKE_DATABASE}\", \"SCHEMA\": \"${SNOWFLAKE_SCHEMA}\" }" \
            -v
      - run: echo deploying the codebase to the dev aws dev env using cloudformation
      - run:
          name: AWS deployment
          command: |
            ls -la;
            make lint data;
            aws --version;
            aws s3 ls;

            echo Here are all the stacks:
            aws cloudformation list-stacks --query "StackSummaries[].StackName";

            # creating a stack if the stack does not exist already
            stack = aws cloudformation describe-stacks --query "Stacks[?contains(StackName,'myteststack')].StackName --output text
            if [[ stack != "myteststack" ]]; then
              echo Creating a stack --region us-east-1
              aws cloudformation create-stack --stack-name myteststack \
              --template-body file://iac/cfn/s3_bucket.yaml \
              --parameters ParameterKey=ProjectName,ParameterValue=S3BucketStack \
              ParameterKey=BucketName,ParameterValue=circle-ci-test-990 \
              ParameterKey=DataLayer,ParameterValue=Raw \
              ParameterKey=Environment,ParameterValue=Dev \
              --region us-east-1
            fi

            [[ $? == 0 ]] && aws s3 sync ./artifact.zip s3://circle-ci-test-990.raw.dev/

  deploy-uat:
    docker:
      - image: cimg/aws:2023.03
    resource_class: small
    steps:
      - run: echo deploying the codebase to the uat env

  deploy-prod:
    docker:
      - image: cimg/aws:2023.03
    resource_class: small
    steps:
      - run: echo deploying the codebase to the prod env

workflows:
  version: 2
  my-workflow:
    jobs:
      - fetch-code
      - build-code:
          requires:
              - fetch-code

      # deploy the build to dev
      - deploy-dev:
          requires:
              - build-code
          context:
            - FluidStreetMachineDev
          filters:
            branches:
              only:
                - /^develop\/.*/

      # deploy the build to uat
      - deploy-to-uat?:
          type: approval
          requires:
            - build-code
          filters:
            branches:
              only:
                - /^release\/.*/
      - deploy-uat:
          requires:
            - deploy-to-uat?
          context:
            - FluidStreetMachineUat
          filters:
            branches:
              only:
                - /^release\/.*/

      # deploy the build to prod
      - deploy-to-prod?:
          type: approval
          requires:
            - deploy-uat
      - deploy-prod:
          requires:
            - deploy-to-prod?
          context:
            - FluidStreetMachineProd
